---
title: "Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# import the data
```{r}
library(readr)
covid <- read_csv("covid_econ.csv")
```

# change variables
```{r cars}
covid$y = covid$GDPCAP
covid$x1 = covid$CODE
covid$x2 = covid$POP
covid$x3 = covid$HDI
covid$x4 = covid$TC
covid$x5 = covid$TD

```

# create new data set at specific date for our model
```{r}
covid = covid[, c('DATE','y','x1','x2','x3','x4','x5')]
df = covid[which(covid$DATE=='2020-08-24'),]
library(tidyr)
df = df %>% drop_na()

```

# build 1st order model: summary, anova(type I and II)
```{r}
reduced.mod = lm(y~x2+x3+x4+x5, data=df)
summary(reduced.mod)
anova(reduced.mod)
library(car)
Anova(reduced.mod, type='II')

plot(reduced.mod)
```

# add interaction terms and form polynomial
# avoid multicollinearity: scale the predictive variables
``` {r}
interdf <- as.data.frame(df$y)
colnames(interdf) = c('y')
interdf$x2 <- scale(df$x2)
interdf$x3 <- scale(df$x3)
interdf$x4 <- scale(df$x4)
interdf$x5 <- scale(df$x5)

interdf$x23 <- interdf$x2*interdf$x3
interdf$x24 <- interdf$x2*interdf$x4
interdf$x25 <- interdf$x2*interdf$x5

interdf$x34 <- interdf$x4*interdf$x3
interdf$x35 <- interdf$x5*interdf$x3

interdf$x45 <- interdf$x4*interdf$x5

interdf$x22 <- (interdf$x2)^2
interdf$x33 <- (interdf$x3)^2
interdf$x44 <- (interdf$x4)^2
interdf$x55 <- (interdf$x5)^2

new.model <- lm(df$y~x2+x3+x4+x5+x23+x24+x25+x34+x35+x45+x22+x33+x44+x55, interdf)
summary(new.model)
anova(new.model)

#H0: All the betas fir the interactive and second order terms are 0
#Ha: Not all of them are zero
SSR_interactiveGiven_x2x3x4x5 = (36.23+.79+.03+1.26+4.36+5.92+7.48+4.38+11.15+.03)/10
SSE = 329.72/165
(F_s = SSR_interactiveGiven_x2x3x4x5/SSE)
qf(.95, 10, 165)
#since 3.584541 > 1.88848, we reject the null hypothesis and conclude that a first order model is not adequate

Anova(new.model, type='II')


```

#1st order MLR diagnostic reduced.mod
```{r}
#residualPlots(reduced.mod)

#Check constant variance
#library(onewaytests)
#library(ggplot2)
#df$group <- cut_number(df$y, 5)
#df$residual <- reduced.mod$residuals
#bf.test(residual~group, df)

#Check normal
#shapiro.test(df$residual)
#qqnorm(df$residual)
#qqline(df$residual)


```


# Model selection
```{r}
library(ALSM)
(bs <- BestSub(interdf[,2:15], interdf$y, num = 1))
#choose model lm(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf)
best.mod <- lm(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf)
summary(best.mod)
anova(best.mod)
Anova(best.mod, type='II')
```

# Check assumptions
```{r}
# residual plots: linear, normal, const var
par(mfrow=c(2,2))
plot(best.mod)

# check constant variance
library(onewaytests)
library(ggplot2)
interdf$group <- cut_number(interdf$y, 5)
interdf$residual <- best.mod$residuals
bf.test(residual~group, interdf, alpha=0.05)

# check normality
shapiro.test(interdf$residual)


```

# Model diagonal
```{r}
# residualPlots(best.mod)

# Partial correlation plot
library(car)
avPlots(best.mod)
```
# influential points
```{r}
# check outliers and influential points
#DFFITS
dff <- dffits(best.mod)
dff[which(abs(dff)>1)]

#Cook's disatnce
cd <- cooks.distance(best.mod)
cd[which(qf(0.2,10, 170) < abs(cd) & abs(cd) < qf(0.5, 10,170))] #moderate influential
cd[which(abs(cd) > qf(0.5, 10,170))] #major influential

#DFBETAS
d <- dfbetas(best.mod)
d[which(abs(d[, 2])>1 & abs(d[,3])>1 &abs(d[,4])>1 &abs(d[,5])>1 &abs(d[,6])>1 & 
          abs(d[,7])>1 &abs(d[,8])>1 &abs(d[,9])>1) &abs(d[,10]>1)]
```

# multicollinearity
```{r}
# correlation between explanatory variables
explan <- cbind(interdf$x2, interdf$x3, interdf$x4, interdf$x5, 
                interdf$x23,interdf$x35,interdf$x22,interdf$x33,interdf$x44)
pairs(explan)
cor(explan)

#VIF
library(fmsb)
VIF(lm(x2~x3+x4+x5+x23+x35+x22+x33+x44, interdf))
VIF(lm(x3~x2+x4+x5+x23+x35+x22+x33+x44, interdf))
VIF(lm(x4~x2+x3+x5+x23+x35+x22+x33+x44, interdf))
VIF(lm(x5~x2+x3+x4+x23+x35+x22+x33+x44, interdf))
VIF(lm(x23~x2+x3+x4+x5+x35+x22+x33+x44, interdf))
VIF(lm(x35~x2+x3+x4+x5+x23+x22+x33+x44, interdf))
VIF(lm(x22~x2+x3+x4+x5+x23+x35+x33+x44, interdf))
VIF(lm(x33~x2+x3+x4+x5+x23+x35+x22+x44, interdf))
VIF(lm(x44~x2+x3+x4+x5+x23+x35+x22+x33, interdf))

```

# Remedy
```{r}
library(MASS)
#robust regression
robust.bestmod<-rlm(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf, psi=psi.bisquare)
summary(robust.bestmod)
#Check assumptions
interdf$group <- cut_number(interdf$y, 5)
interdf$residual <- robust.bestmod$residuals
bf.test(residual~group, interdf)
shapiro.test(interdf$residual)
#Still violate, the outlier is not the only reason for the violation of contant 
#error variance and normality


#WLS
shadow.mod <- best.mod
for(i in seq(1,12,1)) {
  wts1 <- 1/fitted(lm(abs(residuals(shadow.mod))~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf))^2
  shadow.mod <- lm(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, weight = wts1, interdf)
  i = i+1
}
  #bftest again
interdf$group <- cut_number(interdf$y, 5)
interdf$residual <- shadow.mod$residuals
bf.test(residual~group, interdf)
best.mod <- shadow.mod
summary(best.mod )
anova(best.mod)


#ridge regression
library(MASS)
library(lmridge)
ridge.bestmod <- lmridge(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf, K = seq(0,1,0.02))
plot(ridge.bestmod)
vif.lmridge(ridge.bestmod) # choose k = 0.12
# vif.lmridge(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf, K = seq(0.14,0.14))
ridge.bestmod <- lmridge(y~x2+x3+x4+x5+x23+x35+x22+x33+x44, interdf, K = seq(0.12,0.12))
summary(ridge.bestmod)


#Combine ridge and WLS
library(glmnet)
x <- cbind(interdf$x2,interdf$x3,interdf$x4,interdf$x5,interdf$x23, interdf$x35,
           interdf$x22,interdf$x33,interdf$x44)
final.best.mod <- glmnet(x, interdf$y, weights = wts1, alpha = 0, lambda = 0.12)
  #calculate r^2
y_predicted <- predict(final.best.mod, s = .12, newx = x)
(SST = sum(wts1*(interdf$y - weighted.mean(interdf$y, wts1))^2))
(SSE = sum(wts1*(y_predicted - interdf$y)^2))
(rsq = 1-(SSE/SST))
  #Coefficients
final.best.mod$a0
final.best.mod$beta





```

